{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Load csv file to BigQuery"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "TABLE_NAME=\"sample\" "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "### generate connection\n",
    "import pandas as pd\n",
    "query = f\"select * from {TABLE_NAME}\"\n",
    "data = pd.read_sql(query, con=conn)\n",
    "data.to_csv(f\"{TABLE_NAME}.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CREATE TABLE and INSERT by SQL"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "project = \"projectID\"\n",
    "dataset = \"datastet\""
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Created table innate-plexus-345505.compustat.sec_mthprc_bq\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "%%time\n",
    "def upload_csv(file, table_name):\n",
    "    table_id = f\"{project}.{dataset}.{table_name}\"\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "    source_format=bigquery.SourceFormat.CSV, skip_leading_rows=1, autodetect=True,\n",
    "    )\n",
    "\n",
    "    with open(file, \"rb\") as source_file:\n",
    "        job = client.load_table_from_file(source_file, table_id, job_config=job_config)\n",
    "\n",
    "    job.result()  # Waits for the job to complete.\n",
    "\n",
    "    table = client.get_table(table_id)  # Make an API request.\n",
    "    print(\n",
    "        \"Loaded {} rows and {} columns to {}\".format(\n",
    "            table.num_rows, len(table.schema), table_id\n",
    "        )\n",
    "    )\n",
    "\n",
    "upload_csv(f\"{TABLE_NAME}.csv\", TABLE_NAME+\"_csv\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded 6667519 rows and 12 columns to innate-plexus-345505.compustat.sec_mthprc_csv\n",
      "CPU times: user 358 ms, sys: 461 ms, total: 819 ms\n",
      "Wall time: 36.1 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "%%time\n",
    "def upload_gcs(uri, table_name):\n",
    "    table_id = f\"{project}.{dataset}.{table_name}\"\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "    source_format=bigquery.SourceFormat.CSV, skip_leading_rows=1, autodetect=True,\n",
    "    )\n",
    "\n",
    "    load_job = client.load_table_from_uri(\n",
    "        uri, table_id, job_config=job_config\n",
    "    )  # Make an API request.\n",
    "\n",
    "    load_job.result()  # Waits for the job to complete.\n",
    "\n",
    "    destination_table = client.get_table(table_id)  # Make an API request.\n",
    "    print(\"Loaded {} rows.\".format(destination_table.num_rows))\n",
    "\n",
    "\n",
    "upload_gcs(\"gs://compustat-lake-test/sample.csv\", TABLE_NAME+\"_gcs\") # "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded 6667519 rows.\n",
      "CPU times: user 41.6 ms, sys: 4.49 ms, total: 46.1 ms\n",
      "Wall time: 45.2 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 새로운 데이터를 삽입하고 해당 데이터를 검색할 수 있는지 확인\n",
    "실제 테이블 row수가 6,667,520 -> 6,667,521로 변화된 것을 확인함"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "def run_bigquery(table_name, query):\n",
    "    query_job = client.query(query)\n",
    "    query_job.result()\n",
    "    return query_job"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "insert_sample = \"INSERT INTO compustat.{} VALUES (3288012, 28883, '91', '2100-03-31', null, 5800.0, 'USD', null, 24.0, 24.0, 22.4, 5418) \"\n",
    "run_bigquery(TABLE_NAME+\"_csv\", insert_sample.format(\"sample_csv\"))\n",
    "run_bigquery(TABLE_NAME+\"_gcs\", insert_sample.format(\"sample_gcs\"))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "QueryJob<project=innate-plexus-345505, location=asia-northeast3, id=9d9fa74b-c8e6-415f-a028-53ad3f7d4b74>"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "res1=  run_bigquery(TABLE_NAME+\"_csv\", \"SELECT datadate FROM compustat.sample_csv WHERE datadate = '2100-03-31'\")\n",
    "res2=  run_bigquery(TABLE_NAME+\"_gcs\", \"SELECT datadate FROM compustat.sample_gcs WHERE datadate = '2100-03-31'\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "print(\"RESULT from sample_csv : \", [r for r in res1])\n",
    "print(\"RESULT from sample_gcs : \", [r for r in res2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RESULT from sec_mthprc_csv :  [Row((datetime.date(2100, 3, 31),), {'datadate': 0})]\n",
      "RESULT from sec_mthprc_gcs :  [Row((datetime.date(2100, 3, 31),), {'datadate': 0})]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv-py3.8': venv)"
  },
  "interpreter": {
   "hash": "9f2f17b6d125abd0019a4ab498f57fefc952dad4d73b2494a9ef6ba95ec1cd60"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}